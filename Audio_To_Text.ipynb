{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenAI Whisper**"
      ],
      "metadata": {
        "id": "fTczULfBfq20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrvqnvkmI7LT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8641eb33-6f48-4809-f4be-6079f453efd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-17nfr1du\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-17nfr1du\n",
            "  Resolved https://github.com/openai/whisper.git to commit 0a60fcaa9b86748389a656aa013c416030287d47\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (10.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230918)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230918) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230918) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (3.27.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (3.12.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (17.0.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230918) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230918) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230918) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230918) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798399 sha256=c849d13d613d73423b1531d84016aaedddcad1d2c373c13702e631f4d4805867\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w5rvl197/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230918 tiktoken-0.3.3\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,266 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,342 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 2,950 kB in 4s (790 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "18 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"/content/Seminar_In_Bangkok_Jan25.mp3\" --model medium.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XSWP4myKw6G",
        "outputId": "bf3d56a4-c1aa-41f7-d81e-aae4118a5c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 82%|██████████████████████████████▍      | 1.17G/1.42G [01:25<00:18, 14.8MiB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/whisper\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 444, in cli\n",
            "    model = load_model(model_name, device=device, download_root=model_dir)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/__init__.py\", line 131, in load_model\n",
            "    checkpoint_file = _download(_MODELS[name], download_root, in_memory)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/__init__.py\", line 76, in _download\n",
            "    buffer = source.read(8192)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 466, in read\n",
            "    s = self.fp.read(amt)\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n",
        "#result = model.transcribe(\"/content/Seminar_In_Bangkok_Jan25.mp3\")\n",
        "#print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "QqvN8XaefQCn",
        "outputId": "78f422c6-945f-4605-d6ca-aba58c64088d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6eabda7ff71f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"medium\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#result = model.transcribe(\"/content/Seminar_In_Bangkok_Jan25.mp3\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(result[\"text\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'whisper'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "5rPyESisgDXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model, open('/content/audio_Text.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "eIA7W567gEHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_lines(text, line_limit):\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line) + len(word) + 1 <= line_limit:\n",
        "            current_line += word + \" \"\n",
        "        else:\n",
        "            lines.append(current_line)\n",
        "            current_line = word + \" \"\n",
        "\n",
        "    # Add the last line\n",
        "    if current_line:\n",
        "        lines.append(current_line)\n",
        "\n",
        "    return lines"
      ],
      "metadata": {
        "id": "vbn4F1GBgKPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text['text']\n",
        "text_output_file_path = \"/content/Text.txt\"\n",
        "line_limit = 80\n",
        "lines = split_text_into_lines(result['text'], line_limit)\n",
        "with open(text_output_file_path, \"w\") as text_file:\n",
        "      for line in lines:\n",
        "        text_file.write(line + '\\n')"
      ],
      "metadata": {
        "id": "UVi2aN8pgMob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face **Transformers**"
      ],
      "metadata": {
        "id": "NZAG0B56gQxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/huggingface/transformers -q"
      ],
      "metadata": {
        "id": "QQgwUzfbgVLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "bdeB81bagXMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisper = pipeline('automatic-speech-recognition', model = 'openai/whisper-medium')"
      ],
      "metadata": {
        "id": "LJVRdZZFgZAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = whisper('/content/Seminar_In_Bangkok_Jan25.mp3')\n",
        "text['text']"
      ],
      "metadata": {
        "id": "yM-TyIwbgb8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "yf9GGsjPgi7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_lines(text, line_limit):\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        if len(current_line) + len(word) + 1 <= line_limit:\n",
        "            current_line += word + \" \"\n",
        "        else:\n",
        "            lines.append(current_line)\n",
        "            current_line = word + \" \"\n",
        "\n",
        "    # Add the last line\n",
        "    if current_line:\n",
        "        lines.append(current_line)\n",
        "\n",
        "    return lines"
      ],
      "metadata": {
        "id": "cwGmY3A8gknQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text['text']\n",
        "text_output_file_path = \"/content/Text.txt\"\n",
        "line_limit = 80\n",
        "lines = split_text_into_lines(text['text'], line_limit)\n",
        "with open(text_output_file_path, \"w\") as text_file:\n",
        "      for line in lines:\n",
        "        text_file.write(line + '\\n')"
      ],
      "metadata": {
        "id": "SbjQU4RMgmWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assembly AI"
      ],
      "metadata": {
        "id": "D7W4oj6OgrnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helpful for conversational speeches\n",
        "\n"
      ],
      "metadata": {
        "id": "BoHYWYyOfKeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U assemblyai"
      ],
      "metadata": {
        "id": "6r4VyTqke7j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import assemblyai as aai\n",
        "aai.settings.api_key = f\"c0182d6ca1f74b5c98bfb3c1f0b9bb04\""
      ],
      "metadata": {
        "id": "et-3tRtVfATH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_URL = \"/content/drive/MyDrive/Capstone/Sree.m4a\"\n",
        "config = aai.TranscriptionConfig(speaker_labels=True)"
      ],
      "metadata": {
        "id": "9U9qAia9fGBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbke_v6ghOO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcriber = aai.Transcriber()\n",
        "transcript = transcriber.transcribe(\n",
        "  FILE_URL,\n",
        "  config=config\n",
        ")\n",
        "\n",
        "s=\"\"\n",
        "for utterance in transcript.utterances:\n",
        "  s+=utterance.text\n",
        "  print(f\"Speaker {utterance.speaker}: {utterance.text}\")"
      ],
      "metadata": {
        "id": "Lskp82lWfJpr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}